---
title: "Report_Final_Project"
author: "Ricardo Arturo Figueroa"
date: "2023-11-22"
output: html_document
---

```{r include=FALSE}
library(tidyverse)
library(lattice)
library(caret)
library(class)
library(gmodels)
library(psych)
library(DynamicCancerDriverKM)
library(rpart)
library(randomForest)
library(e1071)
library(kernlab)
```

```{r}
normaldata <-(DynamicCancerDriverKM::BRCA_normal)
dataPt <-(DynamicCancerDriverKM::BRCA_PT)
final_data <- bind_rows(normaldata, dataPt)

rate_min_10 <- final_data %>%
  summarise_all(~ mean(. <400, na.rm = TRUE))
```


```{r}
colmn_delate <- names(rate_min_10[, rate_min_10 >= 0.8])

data_filter <- final_data %>%
  select(-one_of(colmn_delate))

data_filter2 <- data_filter

data_PPI<-(DynamicCancerDriverKM::PPI)

data_PPIn <- data_PPI %>%
  pivot_longer(cols = c(`Input-node Gene Symbol`, `Output-node Gene Symbol`), names_to = "variable", values_to = "gen") %>%
  group_by(gen, variable) %>%
  summarise(frecuencia = n()) %>%
  pivot_wider(names_from = variable, values_from = frecuencia, values_fill = 0)

data_PPInR <- data_PPIn %>%
  mutate(total_mode = `Input-node Gene Symbol` + `Output-node Gene Symbol`) %>%
  select(total_mode) %>%
  arrange(desc(total_mode))

print(data_PPInR)

data_filter_x<-colnames(data_filter)[ 8:ncol(data_filter)]
aux2 <- AMCBGeneUtils::changeGeneId(data_filter_x, from = "Ensembl.ID")

names(data_filter)[8:12631] <- aux2$HGNC.symbol

final_data_gen <- colnames(data_filter)

data_PPInR_filtrado <- data_PPInR %>%
  filter(gen %in% final_data_gen)
```


# k-NN model
```{r}
Predictors <- as.vector(head(data_PPInR_filtrado[, 1], 100))
Predictors <- as.character(unlist(Predictors))

colnames(data_filter)[is.na(colnames(data_filter))] <- paste0("xs", seq_along(colnames(data_filter) == ""))
set.seed(13)

data2_filter <- data_filter %>%
  group_by(sample_type) %>%
  sample_n(123, replace = TRUE) %>%
  ungroup()

sample.index <- sample(1:nrow(data2_filter), nrow(data2_filter) * 0.6, replace = FALSE)

train.data <- data2_filter[sample.index, c(Predictors, "sample_type"), drop = FALSE]
test.data <- data2_filter[-sample.index, c(Predictors, "sample_type"), drop = FALSE]

train.data$sample_type <- factor(train.data$sample_type)
test.data$sample_type <- factor(test.data$sample_type)
```

# Train the k-NN model
```{r}
ctrl <- trainControl(method = "cv", p = 0.6)
knnFit <- train(sample_type ~ .,
                data = train.data,
                method = "knn",
                trControl = ctrl,
                preProcess = c("range"),  # c("center", "scale") for z-score
                tuneLength = 50)
```

# Plot k-NN model
```{r}
plot(knnFit)
knnPredict <- predict(knnFit, newdata = test.data)
```

# Create the confusion matrix for k-NN
```{r}
confusionMatrix(data = knnPredict, reference = test.data$sample_type)
```

# Linear regression
```{r}
data2_filter <- data2_filter %>%
  mutate(sample_type = ifelse(sample_type == "Solid Tissue Normal", 1, 0))

train.data <- data2_filter[sample.index, c(Predictors, "sample_type"), drop = FALSE]
test.data <- data2_filter[-sample.index, c(Predictors, "sample_type"), drop = FALSE]
```

# Fit linear regression model
```{r}
ins_model <- lm(sample_type ~ ., data = train.data)
```

# Summary of linear regression model
```{r}
summary(ins_model)
```

# Train the linear regression model
```{r}
train.control <- trainControl(method = "cv", number = 10)
model <- train(sample_type ~ .,
               data = train.data,
               method = "lm",
               trControl = train.control)
```

# Summarize the results of linear regression model
```{r}
print(model)

fit <- rpart(sample_type ~ .,
             method = "anova",
             data = data_filter[, c(Predictors, "sample_type")],
             control = rpart.control(xval = 10))
```

# Print the decision tree
```{r}
print(fit)
```

# Plot the decision tree
```{r}
rpart.plot::rpart.plot(fit)
```

## First Random Forest
```{r}
fit.rf <- randomForest(sample_type ~ .,
                       data = data2_filter[, c(Predictors, "sample_type")])
prediction.rf <- predict(fit.rf, test.data)
table(test.data$sample_type, prediction.rf)
```

## Second Random Forest
```{r}
fit.rf <- randomForest(sample_type ~ .,
                       data = data2_filter[, c(Predictors, "sample_type")])

prediction.rf <- predict(fit.rf, test.data)
output <- data.frame(Actual = test.data$sample_type, Predicted = prediction.rf)
RMSE = sqrt(sum((output$Actual - output$Predicted)^2) / nrow(output))

print(head(output))
```

######vector
# Convierte la variable de respuesta a factor si no lo está
```{r}
data2_filter$sample_type <- as.factor(data2_filter$sample_type)
```

# Divide los datos en conjuntos de entrenamiento y prueba
```{r}
set.seed(13)
sample.index <- sample(1:nrow(data2_filter), nrow(data2_filter) * 0.7, replace = FALSE)
train.data <- data2_filter[sample.index, c(Predictors, "sample_type"), drop = FALSE]
test.data <- data2_filter[-sample.index, c(Predictors, "sample_type"), drop = FALSE]
```

# Realiza la búsqueda de hiperparámetros con e1071
```{r}
tune_out <- tune(svm,
                 sample_type ~ .,
                 data = train.data,
                 kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
```

# Extrae el mejor modelo
```{r}
best_model <- tune_out$best.model
```

# Configura el modelo SVM con un kernel lineal utilizando los mejores hiperparámetros
```{r}
svm_model <- svm(sample_type ~ ., data = train.data, kernel = "linear", cost = best_model[["cost"]])
```

# Realiza predicciones en el conjunto de prueba
```{r}
svm_predict <- predict(svm_model, newdata = test.data)
```

# Evalúa el rendimiento del modelo
```{r}
confusionMatrix(data = svm_predict, reference = test.data$sample_type)
```

# Realiza la búsqueda de hiperparámetros con e1071
```{r}
tune_out <- tune(svm,
                 sample_type ~ .,
                 data = train.data,
                 kernel = "radial",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))

best_model <- tune_out$best.model

svm_model <- svm(sample_type ~ ., data = train.data, kernel = "radial", cost = best_model[["cost"]])
```

# Realiza predicciones en el conjunto de prueba
```{r}
svm_predict <- predict(svm_model, newdata = test.data)
```

# Evalúa el rendimiento del modelo
```{r}
library(caret)
confusionMatrix(data = svm_predict, reference = test.data$sample_type)
```

##Segunda Parte
```{r}
folder<-dirname(rstudioapi::getSourceEditorContext()$path)
parentFolder <-dirname(folder)

DataBulks <- file.path(paste0(parentFolder, "/ExperimentsBulk.rdata"))
load(DataBulks)
ls()

gen_scores <- results[["ENSG00000145675"]][["geneScore"]]
View(gen_scores)

gen_scores2<- gen_scores%>%arrange(desc(score))
score_column <- gen_scores2$features
```

# Obtén la columna "features" de gen_scores2
```{r}
features_column <- gen_scores2$features
```

# Aplica la función changeGeneId a los valores de la columna "features"
```{r}
gen_scores2$features <- AMCBGeneUtils::changeGeneId(features_column, from = "Ensembl.ID")$HGNC.symbol

gen_scores2_filter <- gen_scores2 %>%
  filter(features %in% final_data_gen) #2

Predictors_2 <- head(gen_scores2_filter$features, 100)
```

# Convierte a caracteres si es necesario
```{r}
Predictors_2 <- as.character(Predictors_2)

data2_filter2 <- data_filter %>%
  group_by(sample_type) %>%
  sample_n(123, replace = TRUE) %>%
  ungroup()

sample.index <- sample(1:nrow(data2_filter2), nrow(data2_filter2) * 0.7, replace = FALSE)

train.data <- data2_filter2[sample.index, c(Predictors_2, "sample_type"), drop = FALSE]
test.data <- data2_filter2[-sample.index, c(Predictors_2, "sample_type"), drop = FALSE]

train.data$sample_type <- factor(train.data$sample_type)
test.data$sample_type <- factor(test.data$sample_type)

```

# Train the k-NN model
```{r}
ctrl <- trainControl(method = "cv", p = 0.7)
knnFit <- train(sample_type ~ .,
                data = train.data,
                method = "knn",
                trControl = ctrl,
                preProcess = c("range"),  # c("center", "scale") for z-score
                tuneLength = 50)
```


# Plot k-NN model
```{r}
plot(knnFit)
```

# Make predictions with k-NN
```{r}
knnPredict <- predict(knnFit, newdata = test.data)
```

# Create the confusion matrix for k-NN
```{r}
confusionMatrix(data = knnPredict, reference = test.data$sample_type)
```

# Linear regression
```{r}
data2_filter2 <- data2_filter2  %>%
  mutate(sample_type = ifelse(sample_type == "Solid Tissue Normal", 1, 0))

train.data <- data2_filter2[sample.index, c(Predictors, "sample_type"), drop = FALSE]
test.data <- data2_filter2[-sample.index, c(Predictors, "sample_type"), drop = FALSE]
```

# Fit linear regression model
```{r}
ins_model <- lm(sample_type ~ ., data = train.data)
```

# Summary of linear regression model
```{r}
summary(ins_model)
```

# Train the linear regression model
```{r}
train.control <- trainControl(method = "cv", number = 10)
model <- train(sample_type ~ .,
               data = train.data,
               method = "lm",
              trControl = train.control)
```

# Summarize the results of linear regression model
```{r}
print(model)

```

##arboles de decision
```{r}
fit <- rpart(sample_type ~ .,
             method = "anova",
             data = data2_filter2[, c(Predictors, "sample_type")],
             control = rpart.control(xval = 10))
```

# Print the decision tree
```{r}
print(fit)
```

# Plot the decision tree
```{r}
rpart.plot::rpart.plot(fit)
```

###### Bosques aleatorios
```{r}
fit.rf <- randomForest(sample_type ~ .,
                       data = data2_filter2[, c(Predictors, "sample_type")])
prediction.rf <- predict(fit.rf, test.data)
table(test.data$sample_type, prediction.rf)


fit.rf <- randomForest(sample_type ~ .,
                       data = data2_filter2[, c(Predictors, "sample_type")])


prediction.rf <- predict(fit.rf, test.data)
output <- data.frame(Actual = test.data$sample_type, Predicted = prediction.rf)
RMSE = sqrt(sum((output$Actual - output$Predicted)^2) / nrow(output))

print(head(output))
```

#######################################
```{r}
data2_filter2$sample_type <- as.factor(data2_filter2$sample_type)


set.seed(123)
sample.index <- sample(1:nrow(data2_filter2), nrow(data2_filter2) * 0.7, replace = FALSE)
train.data <- data2_filter2[sample.index, c(Predictors, "sample_type"), drop = FALSE]
test.data <- data2_filter2[-sample.index, c(Predictors, "sample_type"), drop = FALSE]


tune_out <- tune(svm,
                 sample_type ~ .,
                 data = train.data,
                 kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))


best_model <- tune_out$best.model


svm_model <- svm(sample_type ~ ., data = train.data, kernel = "linear", cost = best_model[["cost"]])


svm_predict <- predict(svm_model, newdata = test.data)



confusionMatrix(data = svm_predict, reference = test.data$sample_type)

tune_out <- tune(svm,
                 sample_type ~ .,
                 data = train.data,
                 kernel = "radial",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))

best_model <- tune_out$best.model

svm_model <- svm(sample_type ~ ., data = train.data, kernel = "radial", cost = best_model[["cost"]])

svm_predict <- predict(svm_model, newdata = test.data)


confusionMatrix(data = svm_predict, reference = test.data$sample_type)
```

# Realiza la búsqueda de hiperparámetros con e1071
```{r}
tune_out <- tune(svm,
                 sample_type ~ .,
                 data = train.data,
                 kernel = "sigmoid",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))

best_model <- tune_out$best.model

svm_model <- svm(sample_type ~ ., data = train.data, kernel = "sigmoid", cost = best_model[["cost"]])
```

# Realiza predicciones en el conjunto de prueba
```{r}
svm_predict <- predict(svm_model, newdata = test.data)
```

# Evalúa el rendimiento del modelo
```{r}
confusionMatrix(data = svm_predict, reference = test.data$sample_type)
```
